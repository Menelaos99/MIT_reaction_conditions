{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBvyzj9tVhI4",
        "outputId": "b7aa7d07-e2b8-4baa-cfd2-389f1f72d61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8lTf-nWVk6i",
        "outputId": "1dcd8ad5-95b6-4094-e4b0-32f3c380d008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MIT project\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/MIT project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdsalKVKVqd6",
        "outputId": "50f2fa69-63a8-4781-9af7-c0af15edd108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: periodictable in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from periodictable) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from periodictable) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install periodictable\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2HgO-LbVrQJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "# from classes import *\n",
        "# from exclude import *\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "import matplotlib as plt\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFRrr0z3V6yX"
      },
      "outputs": [],
      "source": [
        "# Complete periodic table with element positions (index starts from 1)\n",
        "periodic_table = {\n",
        "    'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10,\n",
        "    'Na': 11, 'Mg': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20,\n",
        "    'Sc': 21, 'Ti': 22, 'V': 23, 'Cr': 24, 'Mn': 25, 'Fe': 26, 'Co': 27, 'Ni': 28, 'Cu': 29, 'Zn': 30,\n",
        "    'Ga': 31, 'Ge': 32, 'As': 33, 'Se': 34, 'Br': 35, 'Kr': 36, 'Rb': 37, 'Sr': 38, 'Y': 39, 'Zr': 40,\n",
        "    'Nb': 41, 'Mo': 42, 'Tc': 43, 'Ru': 44, 'Rh': 45, 'Pd': 46, 'Ag': 47, 'Cd': 48, 'In': 49, 'Sn': 50,\n",
        "    'Sb': 51, 'Te': 52, 'I': 53, 'Xe': 54, 'Cs': 55, 'Ba': 56, 'La': 57, 'Ce': 58, 'Pr': 59, 'Nd': 60,\n",
        "    'Pm': 61, 'Sm': 62, 'Eu': 63, 'Gd': 64, 'Tb': 65, 'Dy': 66, 'Ho': 67, 'Er': 68, 'Tm': 69, 'Yb': 70,\n",
        "    'Lu': 71, 'Hf': 72, 'Ta': 73, 'W': 74, 'Re': 75, 'Os': 76, 'Ir': 77, 'Pt': 78, 'Au': 79, 'Hg': 80,\n",
        "    'Tl': 81, 'Pb': 82, 'Bi': 83, 'Po': 84, 'At': 85, 'Rn': 86, 'Fr': 87, 'Ra': 88, 'Ac': 89, 'Th': 90,\n",
        "    'Pa': 91, 'U': 92, 'Np': 93, 'Pu': 94, 'Am': 95, 'Cm': 96, 'Bk': 97, 'Cf': 98, 'Es': 99, 'Fm': 100,\n",
        "    'Md': 101, 'No': 102, 'Lr': 103, 'Rf': 104, 'Db': 105, 'Sg': 106, 'Bh': 107, 'Hs': 108, 'Mt': 109,\n",
        "    'Ds': 110, 'Rg': 111, 'Cn': 112, 'Nh': 113, 'Fl': 114, 'Mc': 115, 'Lv': 116, 'Ts': 117, 'Og': 118\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK1uy8xZV7Yh"
      },
      "outputs": [],
      "source": [
        "# Function to parse the chemical formula\n",
        "def parse_formula(formula):\n",
        "    # Pattern to match elements, counts, and groups with parentheses\n",
        "    #pattern = r'([A-Z][a-z]?|\\([^\\(\\)]+\\))(\\d*)'\n",
        "    # new pattern to accept non integer numbers\n",
        "    pattern = r'([A-Z][a-z]?|\\([^\\(\\)]+\\))(\\d*\\.?\\d*)'\n",
        "    matches = re.findall(pattern, formula)\n",
        "    composition = defaultdict(float)\n",
        "\n",
        "    def add_composition(comp_dict):\n",
        "        for element, count in matches:\n",
        "            if count == '':\n",
        "                count = 1\n",
        "            else:\n",
        "                count = float(count)\n",
        "            if element.startswith('('):\n",
        "                # Remove parentheses and parse the inner formula\n",
        "                inner_formula = element[1:-1]\n",
        "                inner_composition = parse_formula(inner_formula)\n",
        "\n",
        "                for inner_element, inner_count in inner_composition.items():\n",
        "                    comp_dict[inner_element] += inner_count * count\n",
        "            else:\n",
        "                comp_dict[element] += count\n",
        "\n",
        "    add_composition(composition)\n",
        "\n",
        "    return composition\n",
        "\n",
        "def parse_prettyformula(formula):\n",
        "    pattern = r'([A-Z][a-z]?)(\\d*)'\n",
        "    matches = re.findall(pattern, formula)\n",
        "    composition=defaultdict(int)\n",
        "    for element, count in matches:\n",
        "        if count=='' or count == None:\n",
        "            count=1\n",
        "        composition[element]= int(count)\n",
        "    return composition\n",
        "\n",
        "\n",
        "# Function to create the compositional vector\n",
        "def encode_compositional_vector(formula):\n",
        "    composition = parse_formula(formula)\n",
        "    total_atoms = sum(composition.values())\n",
        "    vector = [0] * len(periodic_table)  # Create a zero vector with length equal to the number of elements\n",
        "\n",
        "    for element, count in composition.items():\n",
        "        index = periodic_table[element]\n",
        "        vector[index - 1] = count / total_atoms  # Convert to fraction\n",
        "\n",
        "    return vector\n",
        "\n",
        "\n",
        "# input: list of materials\n",
        "# output: list of compositional vectors\n",
        "def convertFormulaToVectors(formula:list):\n",
        "    output=list()\n",
        "    for material in formula:\n",
        "        output.append(encode_compositional_vector(material))\n",
        "    return output\n",
        "\n",
        "# concatenates precursors and targets to a 1 dimensional array\n",
        "#input: list of compositional vectors\n",
        "def concatenate(precursors:list, targets:list):\n",
        "    maxPrecursors= 6\n",
        "    maxTargets=6\n",
        "    vectorLength=118\n",
        "\n",
        "    precursors.append((maxPrecursors-len(precursors))*(vectorLength*[0]))\n",
        "    targets.append((maxTargets-len(targets))*(vectorLength*[0]))\n",
        "\n",
        "    return np.concatenate([np.concatenate(precursors),np.concatenate(targets)])\n",
        "\n",
        "#input: list of compositional vectors\n",
        "# output: ML ready summed up version\n",
        "def sumCompositional(precursors:list, targets:list):\n",
        "    prec=list()\n",
        "    for i in range(len(precursors[0])):\n",
        "        num=0\n",
        "        for k in range(len(precursors)):\n",
        "            num+=precursors[k][i]\n",
        "        prec.append(num)\n",
        "\n",
        "    targ=list()\n",
        "    for i in range(len(targets[0])):\n",
        "        num=0\n",
        "        for k in range(len(targets)):\n",
        "            num+=targets[k][i]\n",
        "        targ.append(num)\n",
        "\n",
        "    return np.concatenate([prec,targ])\n",
        "\n",
        "\n",
        "#input: lhs and rhs to make it ML ready\n",
        "def transform(leftSide:str, rightSide:str, concat=False):\n",
        "    leftSide.replace(\"[\",\"(\")\n",
        "    leftSide.replace(\"]\",\")\")\n",
        "    leftSide.replace(\"·\",\"+\")\n",
        "    rightSide.replace(\"[\",\"(\")\n",
        "    rightSide.replace(\"]\",\")\")\n",
        "    rightSide.replace(\"·\",\"+\")\n",
        "\n",
        "    precursors=leftSide.split(\"+\")\n",
        "    precursors=list(map(str.strip, precursors))\n",
        "\n",
        "    targets=rightSide.split(\"+\")\n",
        "    targets=list(map(str.strip, targets))\n",
        "\n",
        "    precVectors=convertFormulaToVectors(precursors)\n",
        "    targVectors=convertFormulaToVectors(targets)\n",
        "\n",
        "    #concatenate or sum\n",
        "    if concat:\n",
        "        LMready=concatenate(precVectors,targVectors)\n",
        "    else:\n",
        "        LMready=sumCompositional(precVectors,targVectors)\n",
        "\n",
        "    return LMready\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAqgaHRqWUXr"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(236, 360)\n",
        "        self.fc2 = nn.Linear(360, 180)\n",
        "        self.fc3 = nn.Linear(180, 100)\n",
        "        self.fc4 = nn.Linear(100, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = torch.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n",
        "model = NN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "Vjipf9kQZYjG",
        "outputId": "f972190e-7ba5-4ea6-e6ce-53ab55ce2f00"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'lhs'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lhs'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1242d1aa3bdb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data/reaction_entries.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lhs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rhs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcalc_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calcination_temp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lhs'"
          ]
        }
      ],
      "source": [
        "path = os.getcwd()\n",
        "df = pd.read_excel(path + '/data/reaction_entries.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVxcBz33ajhM",
        "outputId": "d7f5edd6-4cc8-41e2-fb08-7c98bfdf3cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4765, 236])\n",
            "torch.Size([4765])\n",
            "453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-91-266a8d1530c3>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X, dtype=torch.float32)  # Ensure dtype is float32\n",
            "<ipython-input-91-266a8d1530c3>:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(y, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "TASK = 'calc'\n",
        "\n",
        "lhs = df['LHS']\n",
        "rhs = df['RHS']\n",
        "\n",
        "calc_temp = df['calcination_temp']\n",
        "sintering_temp = df['sintering_temp']\n",
        "\n",
        "calc_temp_nonna = calc_temp.dropna()\n",
        "sintering_temp_nonna = sintering_temp.dropna()\n",
        "\n",
        "bool_calc_temp = calc_temp.notna()\n",
        "bool_sintering_temp = sintering_temp.notna()\n",
        "\n",
        "lhs_actual_calc = df.loc[bool_calc_temp, 'LHS']\n",
        "rhs_actual_calc = df.loc[bool_calc_temp, 'RHS']\n",
        "indexes_non_nan_calc = df.index[bool_calc_temp]\n",
        "\n",
        "lhs_actual_sint = df.loc[bool_sintering_temp, 'LHS']\n",
        "rhs_actual_sint = df.loc[bool_sintering_temp, 'RHS']\n",
        "indexes_non_nan_sint = df.index[bool_sintering_temp]\n",
        "\n",
        "X = []\n",
        "weird = []\n",
        "temp_mask = []\n",
        "if TASK.lower()[0] == 'c':\n",
        "    lhs_calc = list(lhs_actual_calc)\n",
        "    rhs_calc = list(rhs_actual_calc)\n",
        "    for i in range(len(rhs_calc)):\n",
        "      try:\n",
        "        x = transform(lhs_calc[i], rhs_calc[i])\n",
        "        X.append(x)\n",
        "        temp_mask.append(True)\n",
        "      except:\n",
        "        string = f\"lhs:{lhs_calc[i]}, rhs:{rhs_calc[i]}\"\n",
        "        weird.append(string)\n",
        "        temp_mask.append(False)\n",
        "        continue\n",
        "    X = torch.tensor(X)\n",
        "    y = torch.tensor(list(calc_temp_nonna))\n",
        "    y = y[temp_mask]#Filter out the temps of weird elements\n",
        "else:\n",
        "    lhs_sint = list(lhs_actual_sint)\n",
        "    rhs_sint = list(rhs_actual_sint)\n",
        "    for i in range(len(rhs_sint)):\n",
        "      try:\n",
        "        x = transform(lhs_sint[i], rhs_sint[i])\n",
        "        X.append(x)\n",
        "        temp_mask.append(True)\n",
        "      except:\n",
        "        string = f\"lhs:{lhs_sint[i]}, rhs:{rhs_sint[i]}\"\n",
        "        weird.append(string)\n",
        "        temp_mask.append(False)\n",
        "        continue\n",
        "    X = torch.tensor(X)\n",
        "    y = torch.tensor(list(sintering_temp_nonna))\n",
        "    y = y[temp_mask]#Filter out the temps of weird elements\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)\n",
        "data_list = TensorDataset(X, y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(len(weird))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzDjWkOpWWRb"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, device, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    average_loss = running_loss / len(train_loader)\n",
        "    return average_loss\n",
        "\n",
        "def validate(validation_loader, device, model, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    validation_outputs = []\n",
        "    validation_truth = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            validation_outputs.append(outputs.detach().numpy())\n",
        "            validation_truth.append(labels.detach().numpy())\n",
        "\n",
        "    average_loss = running_loss / len(validation_loader)\n",
        "    validation_outputs = np.concatenate(validation_outputs)\n",
        "    validation_truth = np.concatenate(validation_truth)\n",
        "\n",
        "    return average_loss, validation_outputs, validation_truth\n",
        "\n",
        "\n",
        "def test(test_loader, device, model, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    test_outputs = []\n",
        "    test_truth = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            test_outputs.append(outputs.detach().numpy())\n",
        "            test_truth.append(targets.detach().numpy())\n",
        "\n",
        "    average_loss = running_loss / len(test_loader)\n",
        "    test_outputs = np.concatenate(test_outputs)\n",
        "    test_truth = np.concatenate(test_truth)\n",
        "\n",
        "    return average_loss, test_outputs, test_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "tbED6jt3WYS0",
        "outputId": "fb12472e-18ea-476b-e8e6-c327ad22af69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1/714, Train Size: 4282, Validation Size: 6\n",
            "loss: 210.1541013575312\n",
            "Best Validation Loss: 279.1457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 210.81513253966375\n",
            "Best Validation Loss: 262.1667\n",
            "loss: 210.80426515038334\n",
            "loss: 209.4438491081124\n",
            "loss: 209.45552299271768\n",
            "loss: 209.01522901164952\n",
            "loss: 209.86683851213598\n",
            "loss: 209.3789345470827\n",
            "loss: 209.16754116229157\n",
            "loss: 209.4639983675373\n",
            "Batch 2/714, Train Size: 4282, Validation Size: 6\n",
            "loss: 209.55316529345157\n",
            "Best Validation Loss: 226.5285\n",
            "loss: 208.12707912388132\n",
            "loss: 211.48283258124962\n",
            "loss: 207.90568212252944\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-531f8bc57883>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-3dce648e3c9a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, device, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py\u001b[0m in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnermost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         if (\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             and (\n\u001b[1;32m    412\u001b[0m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"_call_impl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_wrapped_call_impl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(obj, is_inlined_call)\u001b[0m\n\u001b[1;32m   3376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mcheck_verbose\u001b[0;34m(obj, is_inlined_call)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m     \u001b[0;31m# Consulte the central trace rules defined in torch._dynamo.trace_rules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m     rule = torch._dynamo.trace_rules.lookup_inner(\n\u001b[0m\u001b[1;32m   3362\u001b[0m         \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mlookup_inner\u001b[0;34m(obj, name, filename, is_direct_call)\u001b[0m\n\u001b[1;32m   3455\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3457\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_direct_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskipped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSkipFunctionVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3459\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mcheck_file\u001b[0;34m(filename, is_inlined_call)\u001b[0m\n\u001b[1;32m   3275\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inlined_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;34m\"\"\"Should skip this file?\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3277\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSkipResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filename is None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_legacy_mod_inlinelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "learning_rate = 0.1\n",
        "sampling_size = 6\n",
        "\n",
        "validation_losses = []\n",
        "training_losses = []\n",
        "\n",
        "best_vals =[]\n",
        "best_models = []\n",
        "best_tests = []\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_test_split_index = int(0.9 * len(data_list))\n",
        "\n",
        "train_val_data = Subset(data_list, range(train_test_split_index))\n",
        "test_data = Subset(data_list, range(train_test_split_index, len(data_list)))\n",
        "\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "data_len = len(train_val_data)\n",
        "\n",
        "num_batches = data_len // sampling_size\n",
        "\n",
        "indices = np.arange(data_len)\n",
        "\n",
        "for i in range(num_batches):\n",
        "    best_val_loss = np.inf\n",
        "\n",
        "    start_index = i * sampling_size\n",
        "\n",
        "    train_indices = np.setdiff1d(indices, val_indices)\n",
        "    val_indices = indices[start_index:start_index + sampling_size]\n",
        "    train_data = Subset(train_val_data, train_indices)\n",
        "    val_data = Subset(train_val_data, val_indices)\n",
        "\n",
        "    print(f\"Batch {i+1}/{num_batches}, Train Size: {len(train_data)}, Validation Size: {len(val_data)}\")\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "    validation_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                        factor=0.8, patience=5,\n",
        "                                                        min_lr=0.0000001)\n",
        "    criterion = nn.L1Loss()\n",
        "    best_validation_loss = float('inf')\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        train_loss = train(train_loader, device, model, optimizer, criterion)\n",
        "        scheduler.step(train_loss)\n",
        "\n",
        "        loss = train(train_loader, device, model, optimizer, criterion)\n",
        "        scheduler.step(loss)\n",
        "\n",
        "        validation_loss, validation_output, validation_truth_temp = validate(validation_loader, device, model, criterion)\n",
        "        # print(f\"Epoch {epoch+1}, Train Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")\n",
        "        if validation_loss < best_validation_loss:\n",
        "            best_validation_loss = validation_loss\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "            best_model = model\n",
        "            best_val_loss = validation_loss\n",
        "            print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Store the best validation loss for the current epoch\n",
        "        validation_losses.append(best_val_loss)\n",
        "        training_losses.append(train_loss)\n",
        "\n",
        "model.load_state_dict(best_model_state)\n",
        "test_loss, test_outputs, test_truth = test(test_loader, device, model, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"validation losses: {validation_losses}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhzqtpijWbIC"
      },
      "outputs": [],
      "source": [
        "# Plotting validation loss and training loss vs. epochs\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(range(1, len(training_losses) + 1), training_losses, marker='o', linestyle='-', color='r', label='Training Loss')\n",
        "plt.plot(range(1, len(validation_losses) + 1), validation_losses, marker='o', linestyle='-', color='b', label='Validation Loss')\n",
        "\n",
        "plt.title('Training and Validation Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jploz9x_WdAx"
      },
      "outputs": [],
      "source": [
        "X = np.random.rand(1000, 119)  # Example: 1000 samples, 10 features\n",
        "y = np.random.rand(1000)      # Example: 1000 target values\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8\n",
        "}\n",
        "\n",
        "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "\n",
        "num_boost_round = 100\n",
        "early_stopping_rounds = 10\n",
        "model = xgb.train(params, dtrain, num_boost_round, evals, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
        "\n",
        "y_pred = model.predict(dtest)\n",
        "test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(f'Test RMSE: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "DUr07aaJWe-t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"{'featurisation': 'mtencoder_512', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\", \"{'featurisation': 'mtencoder_512', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=1\", \"{'featurisation': 'mtencoder_512', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=2\", \"{'featurisation': 'mtencoder_512', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=3\", \"{'featurisation': 'mtencoder_512', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=4\", \"{'featurisation': 'mtencoder_512', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'mtencoder_512', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'mtencoder_512', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'mtencoder_512', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'mtencoder_512', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'mtencoder_512', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'mtencoder_512', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'mtencoder_512', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'mtencoder_512', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'mtencoder_512', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'mtencoder_256', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\", \"{'featurisation': 'mtencoder_256', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=1\", \"{'featurisation': 'mtencoder_256', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=2\", \"{'featurisation': 'mtencoder_256', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=3\", \"{'featurisation': 'mtencoder_256', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=4\", \"{'featurisation': 'mtencoder_256', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'mtencoder_256', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'mtencoder_256', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'mtencoder_256', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'mtencoder_256', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'mtencoder_256', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'mtencoder_256', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'mtencoder_256', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'mtencoder_256', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'mtencoder_256', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'composition', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\", \"{'featurisation': 'composition', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=1\", \"{'featurisation': 'composition', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=2\", \"{'featurisation': 'composition', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=3\", \"{'featurisation': 'composition', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=4\", \"{'featurisation': 'composition', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'composition', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'composition', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'composition', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'composition', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'composition', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'composition', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'composition', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'composition', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'composition', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'matscibert', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\", \"{'featurisation': 'matscibert', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=1\", \"{'featurisation': 'matscibert', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=2\", \"{'featurisation': 'matscibert', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=3\", \"{'featurisation': 'matscibert', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=4\", \"{'featurisation': 'matscibert', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'matscibert', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'matscibert', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'matscibert', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'matscibert', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'matscibert', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'matscibert', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'matscibert', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'matscibert', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'matscibert', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'matminer', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\", \"{'featurisation': 'matminer', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=1\", \"{'featurisation': 'matminer', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=2\", \"{'featurisation': 'matminer', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=3\", \"{'featurisation': 'matminer', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=4\", \"{'featurisation': 'matminer', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'matminer', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'matminer', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'matminer', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'matminer', 'model_type': 'NN', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\", \"{'featurisation': 'matminer', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=0\", \"{'featurisation': 'matminer', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=1\", \"{'featurisation': 'matminer', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=2\", \"{'featurisation': 'matminer', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=3\", \"{'featurisation': 'matminer', 'model_type': 'XGB', 'task': 'sint', 'use_only_target': False, 'concat': False}_split=4\"]\n",
            "[{'epochs': 50, 'base_layer_dim_log': 10, 'batch_size': 6, 'nn_layers': 4, 'n_layers': 1, 'conv_steps': 4}, {'epochs': 33, 'base_layer_dim_log': 10, 'batch_size': 6, 'nn_layers': 4, 'n_layers': 2, 'conv_steps': 4}, {'epochs': 39, 'base_layer_dim_log': 9, 'batch_size': 4, 'nn_layers': 4, 'n_layers': 3, 'conv_steps': 2}, {'epochs': 48, 'base_layer_dim_log': 10, 'batch_size': 4, 'nn_layers': 2, 'n_layers': 3, 'conv_steps': 3}, {'epochs': 33, 'base_layer_dim_log': 10, 'batch_size': 4, 'nn_layers': 2, 'n_layers': 4, 'conv_steps': 3}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_63160/3308839258.py:20: FutureWarning: load_study() got {'study_name'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  study = optuna.study.load_study(study_name, storage=storage_url)\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import sqlite3\n",
        "\n",
        "# Define the storage URL for Optuna\n",
        "storage_url = 'sqlite:////home/students/code/MLP/Menelaos/reaction_conditions/MLP/storage/db_9_4_22_1.sqlite3'\n",
        "\n",
        "# Get the list of Optuna study summaries\n",
        "study_summaries = optuna.study.get_all_study_summaries(storage=storage_url)\n",
        "\n",
        "# Extract the study names from the summaries\n",
        "study_names = [summary.study_name for summary in study_summaries]\n",
        "\n",
        "# Print the study names\n",
        "print(study_names)\n",
        "\n",
        "\n",
        "# Get the hyperparameters for the specified study names\n",
        "study_hyperparams = []\n",
        "for study_name in [study_names[0], study_names[15], study_names[30], study_names[45], study_names[60]]:\n",
        "    study = optuna.study.load_study(study_name, storage=storage_url)\n",
        "    study_hyperparams.append(study.best_params)\n",
        "\n",
        "print(study_hyperparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"{'featurisation': 'mtencoder_512', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\",\n",
              " \"{'featurisation': 'mtencoder_256', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\",\n",
              " \"{'featurisation': 'composition', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\",\n",
              " \"{'featurisation': 'matscibert', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\",\n",
              " \"{'featurisation': 'matminer', 'model_type': 'GNN', 'task': 'sint', 'use_only_target': False}_split=0\"]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[study_names[0], study_names[15], study_names[30], study_names[45], study_names[60]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'epochs': 50,\n",
              "  'base_layer_dim_log': 10,\n",
              "  'batch_size': 6,\n",
              "  'nn_layers': 4,\n",
              "  'n_layers': 1,\n",
              "  'conv_steps': 4},\n",
              " {'epochs': 33,\n",
              "  'base_layer_dim_log': 10,\n",
              "  'batch_size': 6,\n",
              "  'nn_layers': 4,\n",
              "  'n_layers': 2,\n",
              "  'conv_steps': 4},\n",
              " {'epochs': 39,\n",
              "  'base_layer_dim_log': 9,\n",
              "  'batch_size': 4,\n",
              "  'nn_layers': 4,\n",
              "  'n_layers': 3,\n",
              "  'conv_steps': 2},\n",
              " {'epochs': 48,\n",
              "  'base_layer_dim_log': 10,\n",
              "  'batch_size': 4,\n",
              "  'nn_layers': 2,\n",
              "  'n_layers': 3,\n",
              "  'conv_steps': 3},\n",
              " {'epochs': 33,\n",
              "  'base_layer_dim_log': 10,\n",
              "  'batch_size': 4,\n",
              "  'nn_layers': 2,\n",
              "  'n_layers': 4,\n",
              "  'conv_steps': 3}]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study_hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

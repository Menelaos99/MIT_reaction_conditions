{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:11:39.935169Z",
     "start_time": "2024-07-04T19:11:23.870578Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from utils.classes import *\n",
    "from utils.exclude import *\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = r'data/solid-state_dataset_20200713.json'\n",
    "filedata = open(filename, mode='r').read()\n",
    "jsonParse = json.loads(filedata)\n",
    "\n",
    "reactions = [from_dict(reaction, ReactionEntry) for reaction in jsonParse['reactions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:11:46.544590Z",
     "start_time": "2024-07-04T19:11:46.496242Z"
    }
   },
   "outputs": [],
   "source": [
    "def RemoveBadEntries(reactions: list,\n",
    "                        min_precursors = 2,\n",
    "                        remove_bad_doi = True,\n",
    "                        remove_bad_target = True,\n",
    "                        remove_bad_precursor = True, \n",
    "                        remove_duplicates_via_doi = True,\n",
    "                        remove_invalid_coefficients_multiplicities = True,\n",
    "                        use_bad_list = True,\n",
    "                        remove_negative_coefficients = True, \n",
    "                        verbose_output = True) -> List[ReactionEntry]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Filters out bad reaction entries from a given list based on various criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    reactions (list): List of ReactionEntry objects.\n",
    "    min_precursors (int): Minimum number of precursors required. Default is 2.\n",
    "    remove_bad_doi (bool): Flag to remove entries with bad DOIs. Default is True.\n",
    "    remove_bad_target (bool): Flag to remove entries with bad targets. Default is True.\n",
    "    remove_bad_precursor (bool): Flag to remove entries with bad precursors. Default is True.\n",
    "    remove_duplicates_via_doi (bool): Flag to remove duplicate entries via DOI. Default is True.\n",
    "    remove_invalid_coefficients_multiplicities (bool): Flag to remove entries with invalid coefficients or multiplicities. Default is True.\n",
    "    use_bad_list (bool): Flag to use a predefined list of bad entries. Default is True.\n",
    "    remove_negative_coefficients (bool): Flag to remove entries with negative coefficients. Default is True.\n",
    "    verbose_output (bool): Flag to enable verbose output. Default is True.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of filtered ReactionEntry objects.\n",
    "    \"\"\"\n",
    "        \n",
    "    filtered_reactions = []\n",
    "    bad_list = ['*', '-', 'x', '+', '/', 'ac', '(2N)', '(3N)', '(4N)', '(5N)', '(6N)', '7LiOH', '2Ni(OH)2']\n",
    "    isDigitRegex = re.compile(r'^-?\\d+(\\.\\d+)?$')\n",
    "    isNegativeRegex = re.compile(r'^(0*[1-9]\\d*|0*\\d*\\.\\d*[1-9])$')\n",
    "    RegexSelected = isNegativeRegex\n",
    "    if not remove_negative_coefficients:\n",
    "        RegexSelected = isDigitRegex\n",
    "    for reaction in reactions:\n",
    "        rxn: ReactionEntry = reaction\n",
    "        if (verbose_output): print(rxn.reaction_string, end='')\n",
    "        if remove_bad_doi and rxn.doi in BAD_DOI: \n",
    "            if (verbose_output): print(\": REJECTED DUE TO BAD DOI\")\n",
    "            continue\n",
    "        if len(rxn.precursors) < min_precursors: \n",
    "            if (verbose_output): print(\": REJECTED DUE TO LOW PRECURSOR COUNT\")\n",
    "            continue\n",
    "        if remove_bad_target and any(target in BAD_TARGETS for target in (rxn.targets_string)):  \n",
    "            if (verbose_output): print(\": REJECTED DUE TO BAD TARGET\")\n",
    "            continue\n",
    "        if remove_bad_precursor and  any(precursor.material_formula in BAD_PRECURSORS for precursor in rxn.precursors):  \n",
    "            if (verbose_output): print(\": REJECTED DUE TO BAD PRECURSOR\")\n",
    "            continue\n",
    "        # if any([not bool(isDigitRegex.match(s.amount)) for s in rxn.reaction.left_side]):\n",
    "        #     if (verbose_output): print(\": REJECTED DUE TO UNKNOWN COEFFICIENT IN LHS\")\n",
    "        #     continue\n",
    "        # if any([not bool(isDigitRegex.match(s.amount)) for s in rxn.reaction.right_side]):\n",
    "        #     if (verbose_output): print(\": REJECTED DUE TO UNKNOWN COEFFICIENT IN RHS\")\n",
    "        #     continue \n",
    "        if remove_invalid_coefficients_multiplicities and any([not bool(RegexSelected.match(s.amount)) for s in rxn.reaction.left_side]):\n",
    "            if (verbose_output): print(\": REJECTED DUE TO INVALID COEFFICIENT IN LHS\")\n",
    "            continue\n",
    "        if remove_invalid_coefficients_multiplicities and any([not bool(RegexSelected.match(s.amount)) for s in rxn.reaction.right_side]):\n",
    "            if (verbose_output): print(\": REJECTED DUE TO INVALID COEFFICIENT IN RHS\")\n",
    "            continue\n",
    "\n",
    "        found_bad = False\n",
    "        if use_bad_list: \n",
    "            for bad in bad_list:\n",
    "                if(any(bad in target_string for target_string in rxn.targets_string)) \\\n",
    "                or any(bad in precursor.material_formula for precursor in rxn.precursors):\n",
    "                    found_bad = True\n",
    "        \n",
    "        if found_bad:  \n",
    "            if (verbose_output): print(\": REJECTED CHARACTER FROM BAD LIST\")\n",
    "            continue\n",
    "        else:\n",
    "            if (verbose_output): print(\": SELECTED\") \n",
    "            filtered_reactions.append(rxn)\n",
    "    print(\"Filtered\", len(filtered_reactions), \"reactions out of total\", len(reactions))\n",
    "    return filtered_reactions\n",
    "\n",
    "def NormalizePrecursors(reactions: list) -> List[ReactionEntry]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalizes precursor materials in the given list of reactions based on predefined replacements.\n",
    "    \n",
    "    Parameters:\n",
    "    reactions (list): List of ReactionEntry objects.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of ReactionEntry objects with normalized precursors.\n",
    "    \"\"\"\n",
    "\n",
    "    PrecursorMaterialReplacements = {}\n",
    "    for key, value in PREC_REPLACEMENTS.items():\n",
    "        PrecursorKey    = [ material for reaction in reactions for material in reaction.precursors if material.material_formula == key]\n",
    "        PrecursorValue  = [ material for reaction in reactions for material in reaction.precursors if material.material_formula == value]\n",
    "        filtered_reactions = [reaction for reaction in reactions for material in reaction.precursors if key in material.material_formula]\n",
    "        number_replacements = len(filtered_reactions)\n",
    "        if(len(PrecursorKey) > 0):\n",
    "            for rxn in filtered_reactions:\n",
    "                for prec in rxn.precursors:\n",
    "                    if prec.material_formula == PrecursorKey[0].material_formula: \n",
    "                        #print(\"replace here\")\n",
    "                        prec = PrecursorValue[0]\n",
    "                    if PrecursorKey[0].material_formula in rxn.reaction_string:\n",
    "                        rxn.reaction_string.replace(PrecursorKey[0].material_formula, PrecursorValue[0].material_formula)\n",
    "                    # TODO: You still have to replace Formula parts in rxn.reaction. Find a proposal that works.\n",
    "            PrecursorMaterialReplacements[PrecursorKey[0]] = PrecursorValue[0]\n",
    "            print(\"Processed:\", key, '=', value, \": replaced\", number_replacements, \" places\")\n",
    "        else: print(\"Skipped:\", key)\n",
    "    return reactions\n",
    "\n",
    "def RemoveDuplicates(reactions: list) -> List[ReactionEntry]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Placeholder for function to remove duplicates from the list of reactions.\n",
    "    TODO: Integrate all other \"Remove*Duplicates\" Functions\n",
    "\n",
    "    Parameters:\n",
    "    reactions (list): List of ReactionEntry objects.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of ReactionEntry objects without duplicates.\n",
    "    \"\"\"\n",
    "\n",
    "    return reactions\n",
    "\n",
    "def RemoveDOIDuplicates(reactions: list) -> List[ReactionEntry]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Removes duplicate reactions based on DOI and reaction string.\n",
    "    \n",
    "    Parameters:\n",
    "    reactions (list): List of ReactionEntry objects.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of ReactionEntry objects without DOI duplicates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assuming 'reactions' is your list of ReactionEntry objects\n",
    "\n",
    "    # Create a defaultdict to store entries grouped by (doi, reaction_string)\n",
    "    entry_dict = defaultdict(list)\n",
    "    for entry in reactions:\n",
    "        entry_dict[(entry.doi, entry.reaction_string)].append(entry)\n",
    "\n",
    "    # Filter out entries where there are duplicates (keep only the first occurrence)\n",
    "    filtered_reactions_doi = []\n",
    "    seen_keys = set()\n",
    "    for entry in reactions:\n",
    "        key = (entry.doi, entry.reaction_string)\n",
    "        if key not in seen_keys:\n",
    "            seen_keys.add(key)\n",
    "            filtered_reactions_doi.append(entry)\n",
    "    print(\"Filtered\", len(filtered_reactions_doi), \"reactions out of total\", len(reactions))\n",
    "    return filtered_reactions_doi\n",
    "\n",
    "def RemoveNodeMatchDuplicates(reactions: list, verbose_output=False) -> tuple[List[ReactionEntry], defaultdict(list)]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Removes duplicates based on node matches in the reaction entries.\n",
    "    \n",
    "    Parameters:\n",
    "    reactions (list): List of ReactionEntry objects.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of ReactionEntry objects without node match duplicates.\n",
    "    \"\"\"\n",
    "    # Dictionary to store entries grouped by (right_side_tuple, amount_tuple)\n",
    "    duplicate_entries = defaultdict(list)\n",
    "    filtered_reactions_dupForm = []\n",
    "    for entry in reactions:\n",
    "        # Create a tuple representation of right_side\n",
    "        right_side_tuple = tuple((part.amount, part.material) for part in entry.reaction.right_side)\n",
    "\n",
    "        # Create sets of (amount, material) tuples for target and precursors\n",
    "        target_materials = {(comp.amount, comp.formula) for comp in entry.target.composition}\n",
    "        precursor_materials =  {(mat.amount, mat.formula) for composition in (material.composition for material in entry.precursors) for mat in composition}\n",
    "\n",
    "        # Create a tuple for (target materials, precursor materials)\n",
    "        materials_tuple = (frozenset(target_materials), frozenset(precursor_materials))\n",
    "\n",
    "        key = (right_side_tuple, materials_tuple)\n",
    "        duplicate_entries[key].append(entry)\n",
    "\n",
    "    # Now, find and print duplicates\n",
    "    seen_keys = set()\n",
    "    for key, entries in duplicate_entries.items():\n",
    "        if len(entries) > 1:\n",
    "            if key not in seen_keys:\n",
    "                seen_keys.add(key)\n",
    "                filtered_reactions_dupForm.append(entry)\n",
    "            if(verbose_output): print(len(entries), \"\\tDuplicates for: \", end='')\n",
    "            if(verbose_output): print(f\"Right Side: {key[0]}\", end='')\n",
    "            if(verbose_output): print(\"Target materials:\", end='')\n",
    "            if(verbose_output): print(key[1][0], end='')\n",
    "            if(verbose_output): print(\"Precursor materials:\", end='')\n",
    "            if(verbose_output): print(key[1][1], end='')\n",
    "            if(verbose_output): print()\n",
    "            for i in range(len(entries)):\n",
    "                entry = entries[i]\n",
    "                if(verbose_output): print(\"Entry #{}: \".format(i), end='')\n",
    "                calc_operations = [op for op in entry.operations if \"calc\" in op.token]\n",
    "                if(verbose_output): print(\"No. Calcination Operations: {}, \".format(len(calc_operations)))\n",
    "                for op in calc_operations:\n",
    "                    if(verbose_output): print(op)\n",
    "    print(\"Filtered\", len(filtered_reactions_dupForm), \"reactions out of total\", len(reactions))\n",
    "    return filtered_reactions_dupForm, duplicate_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 20093 reactions out of total 31782\n",
      "Filtered 19318 reactions out of total 20093\n"
     ]
    }
   ],
   "source": [
    "badEntriesList = RemoveBadEntries(reactions, verbose_output = False)\n",
    "doiEntriesList = RemoveDOIDuplicates(badEntriesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doiEntriesList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kesava89/repos/ssm-synthesis-data-processing/Preprocessing_m2.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://coder.de.soanpapdi.cloud/home/kesava89/repos/ssm-synthesis-data-processing/Preprocessing_m2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m filtered_final, duplicate_node_match \u001b[39m=\u001b[39m RemoveNodeMatchDuplicates(doiEntriesList)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doiEntriesList' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_final, duplicate_node_match = RemoveNodeMatchDuplicates(doiEntriesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reaction(reaction_string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Splits a chemical reaction string into reactants and products.\n",
    "\n",
    "    Parameters:\n",
    "    reaction_string (str): The reaction string to be split, with reactants and products separated by '=='.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[str, str]: A tuple containing the reactants and products as separate strings.\n",
    "    \"\"\"\n",
    "        \n",
    "    reactants, products = reaction_string.split('==')\n",
    "    reactants = reactants.strip()\n",
    "    products = products.strip()\n",
    "    return reactants, products\n",
    "\n",
    "def parse_chemical_formula(formula):\n",
    "\n",
    "    \"\"\"\n",
    "    Parses a chemical formula into its constituent elements and their multiplicities.\n",
    "\n",
    "    Parameters:\n",
    "    formula (str): The chemical formula to be parsed.\n",
    "\n",
    "    Returns:\n",
    "    List[Tuple[str, str, str]]: A list of tuples, each containing an element, its multiplicity, and its atomic number.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r'([A-Z][a-z]*)(\\d*\\.?\\d*)'\n",
    "    matches = re.findall(pattern, formula)\n",
    "    element_details = []\n",
    "    for match in matches:\n",
    "        element, multiplicity = match\n",
    "        multiplicity = multiplicity if multiplicity else '1'\n",
    "        atomic_number = re.findall(r'\\d+', multiplicity)\n",
    "        atomic_number = atomic_number[0] if atomic_number else '1'\n",
    "        element_details.append((element, multiplicity, atomic_number))\n",
    "    return element_details\n",
    "\n",
    "def extract_element_details(reaction):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts element details from a chemical reaction string.\n",
    "\n",
    "    Parameters:\n",
    "    reaction (str): The reaction string containing elements separated by '+'.\n",
    "\n",
    "    Returns:\n",
    "    List[Tuple[str, str, str]]: A list of tuples containing element details.\n",
    "    \"\"\"\n",
    "\n",
    "    parts = reaction.split('+')\n",
    "    element_details = []\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        element_details.extend(parse_chemical_formula(part))\n",
    "    return element_details\n",
    "\n",
    "def expand_element_details(element_details, prefix):\n",
    "\n",
    "    \"\"\"\n",
    "    Expands element details into a dictionary with a given prefix.\n",
    "\n",
    "    Parameters:\n",
    "    element_details (List[Tuple[str, str, str]]): A list of tuples containing element details.\n",
    "    prefix (str): A prefix for the dictionary keys.\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, str]: A dictionary with element details expanded into key-value pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "    for i, detail in enumerate(element_details):\n",
    "        element, multiplicity, atomic_number = detail\n",
    "        data[f'{prefix}_element_{i+1}'] = element\n",
    "        data[f'{prefix}_multiplicity_{i+1}'] = multiplicity\n",
    "        data[f'{prefix}_atomic_number_{i+1}'] = atomic_number\n",
    "    return data\n",
    "\n",
    "def extract_temperatures(operations):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts sintering and calcination temperatures from a list of operations.\n",
    "\n",
    "    Parameters:\n",
    "    operations (List[Operation]): A list of operations, where each operation has a type and a token.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[float, float]: A tuple containing sintering and calcination temperatures.\n",
    "    \"\"\"\n",
    "\n",
    "    sintering_temp = None\n",
    "    calcination_temp = None\n",
    "    for operation in operations:\n",
    "        if operation.type == 'HeatingOperation':\n",
    "            if operation.token == 'sintered':\n",
    "                sintering_temp = extract_temp(operation.conditions)\n",
    "            elif operation.token == 'calcined':\n",
    "                calcination_temp = extract_temp(operation.conditions)\n",
    "    return sintering_temp, calcination_temp\n",
    "\n",
    "def extract_temp(conditions):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts the temperature from a set of conditions.\n",
    "\n",
    "    Parameters:\n",
    "    conditions (Conditions): Conditions containing heating temperature data.\n",
    "\n",
    "    Returns:\n",
    "    float: The first heating temperature value found, or None if not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    if conditions.heating_temperature:\n",
    "        for temp in conditions.heating_temperature:\n",
    "            if temp.values:\n",
    "                return temp.values[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame([{\n",
    "    'doi': entry.doi,\n",
    "    'paragraph_string': entry.paragraph_string,\n",
    "    'synthesis_type': entry.synthesis_type,\n",
    "    'reaction_string': entry.reaction_string,\n",
    "    'targets_string': entry.targets_string,\n",
    "    'sintering_temp': extract_temperatures(entry.operations)[0],\n",
    "    'calcination_temp': extract_temperatures(entry.operations)[1]\n",
    "} for entry in doiEntriesList])\n",
    "\n",
    "# Apply the function to create new columns\n",
    "df[['input_reaction', 'output_reaction']] = df['reaction_string'].apply(lambda x: pd.Series(split_reaction(x)))\n",
    "df['input_elements'] = df['input_reaction'].apply(extract_element_details)\n",
    "df['output_elements'] = df['output_reaction'].apply(extract_element_details)\n",
    "input_expanded = df['input_elements'].apply(lambda x: pd.Series(expand_element_details(x, 'input')))\n",
    "output_expanded = df['output_elements'].apply(lambda x: pd.Series(expand_element_details(x, 'output')))\n",
    "\n",
    "# Concatenate the expanded details with the original DataFrame\n",
    "df = pd.concat([df, input_expanded, output_expanded], axis=1)\n",
    "\n",
    "# Drop temporary columns\n",
    "df.drop(columns=['input_elements', 'output_elements'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = './reaction_entries.xlsx'\n",
    "df.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code - de-duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "for item, entries in duplicate_node_match.items():\n",
    "    if len(entries) > 1:\n",
    "        entrylist = []\n",
    "        for entry in entries:\n",
    "            entrylist.append(entry.to_dict())\n",
    "        payload[entries[0].reaction_string] = entrylist\n",
    "\n",
    "json_string = json.dumps(payload, indent=4,default=lambda o: o.__dict__)\n",
    "filename = \"output.json\"\n",
    "\n",
    "with open(filename, \"w\") as file:\n",
    "    file.write(json_string)\n",
    "\n",
    "print(f\"JSON data saved to {filename}\")\n",
    "\n",
    "verbose_output = False \n",
    "duplicates = []\n",
    "sum = 0\n",
    "for key, entries in duplicate_node_match.items():\n",
    "        if len(entries) > 1:\n",
    "            for entry in entries:\n",
    "                  duplicates.append({'reaction_string': entry.reaction_string,str(entry.doi): entry})\n",
    "            # sum += len(entries)\n",
    "            # if(verbose_output): print(len(entries), \" Duplicates for: \", end='')\n",
    "            # if(verbose_output): print(f\"Right Side: {key[0]}\", end='')\n",
    "            # if(verbose_output): print(\"Target materials:\", end='')\n",
    "            # if(verbose_output): print(key[1][0], end='')\n",
    "            # if(verbose_output): print(\"Precursor materials:\", end='')\n",
    "            # if(verbose_output): print(key[1][1], end='')\n",
    "            # if(verbose_output): print()\n",
    "            # for i in range(len(entries)):\n",
    "            #     entry = entries[i]\n",
    "            #     if(verbose_output): print(\"Entry #{}: \".format(i), end='')\n",
    "            #     calc_operations = [op for op in entry.operations if \"calc\" in op.token]\n",
    "            #     if(verbose_output): print(\"Reaction String {},\".format(str(entry)))\n",
    "            #     # for op in calc_operations:\n",
    "            #     #     if(verbose_output): print(op)\n",
    "            # print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
